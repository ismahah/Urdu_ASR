{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10140477,"sourceType":"datasetVersion","datasetId":6258678}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# File path to the text file\nfile_path = \"/kaggle/input/new-dataset/new.txt\"\ntext = []\n# Read the file content\nwith open(file_path, 'r', encoding='utf-8') as file:\n    text = file.read()\n\n# Split the text into lines (assuming each line contains a question-answer pair)\nlines = text.strip().split(\"\\n\")\n\n# Split each line into question and answer\nquestions = []\nanswers = []\n\nfor line in lines:\n    question, answer = line.split(\"|\")  # Split the line at the delimiter '|'\n    questions.append(question.strip())  # Remove leading/trailing whitespace\n    answers.append(answer.strip())\n\n# Create a DataFrame\ndf = pd.DataFrame({'Question': questions, 'Answer': answers})\n\n# Display the DataFrame\nprint(df)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:28:40.216240Z","iopub.execute_input":"2024-12-08T16:28:40.217222Z","iopub.status.idle":"2024-12-08T16:28:40.246791Z","shell.execute_reply.started":"2024-12-08T16:28:40.217147Z","shell.execute_reply":"2024-12-08T16:28:40.244951Z"}},"outputs":[{"name":"stdout","text":"                                       Question  \\\n0              ï»¿Ø³Ø¨ Ø³Û’ Ø¨Ø§ÛØ± ÙˆØ§Ù„Ø§ Ø³ÛŒØ§Ø±Û Ú©ÙˆÙ†Ø³Ø§ ÛÛ’ØŸ   \n1        Ø¯ÙˆØ±Ú¾ Ù…ÛŒÚº Ú©ØªÙ†Û’ ÙÛŒØµØ¯ Ù¾Ø§Ù†ÛŒ Ù¾Ø§ÛŒØ§ Ø¬Ø§ØªØ§ ÛÛ’ ØŸ   \n2                     Ú†Ø§Ø±Ø¬ Ú©ÛŒ ÛŒÙˆÙ†Ù¹ Ú©ÛŒØ§ Ú¾ÙˆØªÛŒ Ú¾Û’ØŸ   \n3     ÛØ§Ø¦ÛŒ ÙØ±ÛŒÚ©ÙˆØ¦Ù†Ø³ÛŒ Ú©ÛŒ ÙˆÛŒÙˆ Ù„ÛŒÙ†ØªÚ¾ Ú©ØªÙ†ÛŒ ÛÙˆØªÛŒ ÛÛ’ØŸ   \n4   ÙˆØ§Ø¦Ù¹ Ù…Ù† Ø§Û’ Ú©ÛŒ Ú©Ù…ÛŒ Ø³Û’ Ú©ÙˆÙ† Ø³ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒ ÛÙˆØªÛŒ ÛÛ’ØŸ   \n..                                          ...   \n72                      Ø³Ø±Ø® Ø®Ù„ÛŒÛ’ Ú©ÛØ§Úº Ø¨Ù†ØªÛ’ ÛÛŒÚºØŸ   \n73        Ø§Ù†Ø³Ø§Ù† Ú©Û’ Ø¬Ø³Ù… Ù…ÛŒÚº Ú©ØªÙ†ÛŒ ÛÚˆÛŒØ§Úº ÛÙˆØªÛŒ ÛÛŒÚºØŸ   \n74  Ø§Ù†Ø³Ø§Ù†ÛŒ Ø¯Ù…Ø§Øº Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø¨Ú‘Ø§ Ø­ØµÛ Ú©ÙˆÙ†Ø³Ø§ ÛÙˆØªØ§ ÛÛ’ØŸ   \n75       ÛÚˆÛŒ Ø§ÙˆØ± Ø¯Ø§Ù†Øª Ú©Ø³ Ú†ÛŒØ² Ø³Û’ Ù…Ù„ Ú©Ø± Ø¨Ù†ØªÛ’ ÛÛŒÚºØŸ   \n76      ÛÙ…ÙˆÚ¯Ù„ÙˆØ¨ÛŒÙ† Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø§ÛÙ… Ø±Ú©Ù† Ú©ÛŒØ§ ÛÙˆØªØ§ ÛÛ’ØŸ   \n\n                                               Answer  \n0                    Ø³Ø¨ Ø³Û’ Ø¨Ø§ÛØ± ÙˆØ§Ù„Ø§ Ø³ÛŒØ§Ø±Û Ù†ÛŒÙ¾Ú†ÙˆÙ† ÛÛ’Û”  \n1                Ø¯ÙˆØ¯Ú¾ Ù…ÛŒÚº Ø§Ø³ÛŒ ÙÛŒØµØ¯ Ù¾Ø§Ù†ÛŒ Ù¾Ø§ÛŒØ§ Ø¬Ø§ØªØ§ ÛÛ’Û”  \n2                        Ú†Ø§Ø±Ø¬ Ú©ÛŒ ÛŒÙˆÙ†Ù¹ Ú©Ùˆ Ù„Ù…Ø¨ ÛÙˆØªÛŒ ÛÛ’Û”  \n3          ÛØ§Ø¦ÛŒ ÙØ±ÛŒÚ©ÙˆØ¦Ù†Ø³ÛŒ Ú©ÛŒ ÙˆÛŒÙˆ Ù„ÛŒÙ†ØªÚ¾ Ú†Ú¾ÙˆÙ¹ÛŒ ÛÙˆØªÛŒ ÛÛ’Û”  \n4   ÙˆØ§Ø¦Ù¹ Ù…Ù† Ø§Û’ Ú©ÛŒ Ú©Ù…ÛŒ Ø³Û’Ø±Ø§Øª Ú©Ùˆ Ø§Ù†Ø¯Ú¾Û’ Ù¾Ù† Ú©ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒ ...  \n..                                                ...  \n72                         Ø³Ø±Ø® Ø®Ù„ÛŒÛ’ ÛÚˆÛŒ Ù…ÛŒÚº Ø¨Ù†ØªÛ’ ÛÛŒÚºÛ”  \n73          Ø§Ù†Ø³Ø§Ù† Ú©Û’ Ø¬Ø³Ù… Ù…ÛŒÚº Ø¯Ùˆ Ø³Ùˆ Ú†Ú¾ ÛÚˆÛŒØ§Úº ÛÙˆØªÛŒ ÛÛŒÚºÛ”  \n74        Ø§Ù†Ø³Ø§Ù†ÛŒ Ø¯Ù…Ø§Øº Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø¨Ú‘Ø§ Ø­ØµÛ Ø³Ø±Ø¨Ø±Ù… ÛÙˆØªØ§ ÛÛ’Û”  \n75  ÛÚˆÛŒ Ø§ÙˆØ± Ø¯Ø§Ù†Øª Ú©ÛŒÙ„Ø´ÛŒÙ… Ø§ÙˆØ± ÙØ§Ø³ÙÛŒÙ¹ Ø³Û’ Ù…Ù„ Ú©Ø± Ø¨Ù†ØªÛ’ ÛÛŒÚºÛ”  \n76           ÛÙ…ÙˆÚ¯Ù„ÙˆØ¨ÛŒÙ† Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø§ÛÙ… Ø±Ú©Ù† Ø¢Ø¦Ø±Ù† ÛÙˆØªØ§ ÛÛ’Û”  \n\n[77 rows x 2 columns]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Manually entered conversations\ntext = [\n    \"1. Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ù¹Ú¾ÛŒÚ© ÛÙˆÚºØŒ Ø´Ú©Ø±ÛŒÛ!\",\n    \"2. Ú©ØªÙ†Û’ Ø¨Ø¬Û’ ÛÛŒÚºØŸ | ØªÛŒÙ† Ø¨Ø¬Û’ ÛÛŒÚºÛ”\",\n    \"3. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ù…Ø§Ø±Ú©ÛŒÙ¹ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"4. Ø¢Ø¬ Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ø¢Ø¬ Ú¯Ú¾Ø± Ù¾Ø± Ø¢Ø±Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"5. Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ú©Ø§ÙÛŒ Ù¾Ø³Ù†Ø¯ ÛÛ’ØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"6. Ø¢Ù¾ Ú©Ø§ Ø¯Ù† Ú©ÛŒØ³Ø§ Ú¯Ø²Ø±Ø§ØŸ | Ø¨ÛØª Ø§Ú†Ú¾Ø§ Ú¯Ø²Ø±Ø§ØŒ Ø´Ú©Ø±ÛŒÛ!\",\n    \"7. Ø¢Ù¾ Ú©Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ø±Ù†Ú¯ Ú©ÙˆÙ† Ø³Ø§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ù†ÛŒÙ„Ø§ Ø±Ù†Ú¯ Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"8. Ø¢Ù¾ Ú©ÛØ§Úº Ø±ÛØªÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ù„Ø§ÛÙˆØ± Ù…ÛŒÚº Ø±ÛØªØ§ ÛÙˆÚºÛ”\",\n    \"9. Ú©ÛŒØ§ Ø¢Ù¾ Ù…ØµØ±ÙˆÙ ÛÛŒÚºØŸ | Ù†ÛÛŒÚºØŒ Ù…ÛŒÚº ÙØ§Ø±Øº ÛÙˆÚºÛ”\",\n    \"10. Ø±Ø§Øª Ú©Ø§ Ú©Ú¾Ø§Ù†Ø§ Ú©ÛŒØ§ ÛÛ’ØŸ | Ø¢Ø¬ Ø±Ø§Øª Ù¾Ø§Ø³ØªØ§ Ø¨Ù† Ø±ÛØ§ ÛÛ’Û”\",\n    \"11. Ø¢Ù¾ Ú©ÛŒ Ø¹Ù…Ø± Ú©ØªÙ†ÛŒ ÛÛ’ØŸ | Ù…ÛŒØ±ÛŒ Ø¹Ù…Ø± 25 Ø³Ø§Ù„ ÛÛ’Û”\",\n    \"12. Ú©ÛŒØ§ Ø¢Ù¾ Ù…ÛŒØ±ÛŒ Ù…Ø¯Ø¯ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ø¢Ù¾ Ú©Ùˆ Ú©Ø³ Ú†ÛŒØ² Ú©ÛŒ Ù…Ø¯Ø¯ Ú†Ø§ÛÛŒÛ’ØŸ\",\n    \"13. Ú©ÛŒØ§ Ø¢Ù¾ Ù†Û’ Ú©Ú¾Ø§Ù†Ø§ Ú©Ú¾Ø§ÛŒØ§ØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ø§ÛŒÚ© Ú¯Ú¾Ù†Ù¹Û Ù¾ÛÙ„Û’ Ù„Ù†Ú† Ú©ÛŒØ§ ØªÚ¾Ø§Û”\",\n    \"14. Ø¢Ù¾ Ú©Ø§ ÙÙˆÙ† Ú©ÛØ§Úº ÛÛ’ØŸ | ÙˆÛ Ù¹ÛŒØ¨Ù„ Ù¾Ø± Ù¾Ú‘Ø§ ÛÛ’Û”\",\n    \"15. Ú©ÛŒØ§ Ø¢Ù¾ Ù¹ÛŒ ÙˆÛŒ Ø¯ÛŒÚ©Ú¾ØªÛ’ ÛÛŒÚºØŸ | Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø±ØŒ Ø²ÛŒØ§Ø¯Û ØªØ± Ø±Ø§Øª Ú©ÙˆÛ”\",\n    \"16. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø®Ø±ÛŒØ¯Ø§ØŸ | Ù…ÛŒÚº Ù†Û’ Ø³Ø¨Ø²ÛŒØ§Úº Ø®Ø±ÛŒØ¯ÛŒ ÛÛŒÚºÛ”\",\n    \"17. Ú©ÛŒØ§ Ø¢Ù¾ Ù¾Ø§Ø±Ù¹ÛŒ Ù…ÛŒÚº Ø¢ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ù…ÛŒÚº Ø¢ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"18. Ø¢Ù¾ Ú©ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙ„Ù… Ú©ÙˆÙ† Ø³ÛŒ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ 'Ø´Ø§Ø´Ù†Ú© Ø±ÛŒÚˆÙ…Ù¾Ø´Ù†' Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"19. Ú©ÛŒØ§ Ø¢Ù¾ Ø¢Ø¬ Ú©Ø§Ù… Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ø¨Ø¹Ø¯ Ù…ÛŒÚº Ù…ÛŒÙ¹Ù†Ú¯ ÛÛ’Û”\",\n    \"20. Ø¢Ù¾ Ú©Û’ Ú¯Ú¾Ø± ÙˆØ§Ù„Û’ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ | ÙˆÛ Ø³Ø¨ Ø®ÛŒØ±ÛŒØª Ø³Û’ ÛÛŒÚºØŒ Ø´Ú©Ø±ÛŒÛ!\",\n    \"21. Ø¢Ù¾ ØªÙØ±ÛŒØ­ Ú©Û’ Ù„ÛŒÛ’ Ú©ÛŒØ§ Ú©Ø±ØªÛ’ ÛÛŒÚºØŸ | Ù…Ø¬Ú¾Û’ Ú©ØªØ§Ø¨ÛŒÚº Ù¾Ú‘Ú¾Ù†Ø§ Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"22. Ú©ÛŒØ§ Ù…ÛŒÚº ÛŒÛ Ù„Û’ Ø³Ú©ØªØ§ ÛÙˆÚºØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ø¨Ø§Ù„Ú©Ù„ Ù„Û’ Ù„ÛŒÚºÛ”\",\n    \"23. Ú©ÛŒØ§ Ø¢Ù¾ ØªÚ¾Ú©Û’ ÛÙˆØ¦Û’ ÛÛŒÚºØŸ | ÛØ§ÚºØŒ ØªÚ¾ÙˆÚ‘Ø§ ØªÚ¾Ú©Ø§ ÛÙˆØ§ ÛÙˆÚºÛ”\",\n    \"24. Ø¢Ù¾ Ú©ØªÙ†Û’ Ø¨Ø¬Û’ Ø§Ù¹Ú¾ØªÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº ØµØ¨Ø­ 7 Ø¨Ø¬Û’ Ø§Ù¹Ú¾ØªØ§ ÛÙˆÚºÛ”\",\n    \"25. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ú¾Ø§Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºØŸ | Ù…Ø¬Ú¾Û’ Ù¾ÛŒØ²Ø§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø¯Ù„ Ú†Ø§Û Ø±ÛØ§ ÛÛ’Û”\",\n    \"26. Ú©Ù„ Ø¢Ù¾ Ú©ÛØ§Úº Ú¯Ø¦Û’ ØªÚ¾Û’ØŸ | Ù…ÛŒÚº Ù¾Ø§Ø±Ú© Ú¯ÛŒØ§ ØªÚ¾Ø§Û”\",\n    \"27. Ú©ÛŒØ§ Ø¢Ù¾ Ù†Û’ ÛŒÛ ÙÙ„Ù… Ø¯ÛŒÚ©Ú¾ÛŒ ÛÛ’ØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ù…ÛŒÚº Ù†Û’ Ù¾Ú†Ú¾Ù„Û’ ÛÙØªÛ’ Ø¯ÛŒÚ©Ú¾ÛŒ ØªÚ¾ÛŒÛ”\",\n    \"28. Ø¢Ø¬ Ú©Ø§ Ù…ÙˆØ³Ù… Ú©ÛŒØ³Ø§ ÛÛ’ØŸ | Ø¢Ø¬ Ú©Ø§ Ù…ÙˆØ³Ù… Ø¯Ú¾ÙˆÙ¾ ÙˆØ§Ù„Ø§ Ø§ÙˆØ± Ú¯Ø±Ù… ÛÛ’Û”\",\n    \"29. Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù¾Ø³Ù†Ø¯ ÛÛ’ØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø³Ù†Ù†Ø§ Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"30. Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ú†Ø§Ø¦Û’ Ù¾Ø³Ù†Ø¯ ÛÛ’ØŸ | ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"31. Ø¢Ù¾ Ú©ÛØ§Úº Ú©Ø§Ù… Ú©Ø±ØªÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§ÛŒÚ© Ú©Ù…Ù¾Ù†ÛŒ Ù…ÛŒÚº Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÙˆÚºÛ”\",\n    \"32. Ø¢Ù¾ Ú©Ùˆ Ú©Ø¨ ØªÚ© Ø¢Ù†Ø§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ 10 Ù…Ù†Ù¹ Ù…ÛŒÚº Ø¢Ù†Ø§ ÛÛ’Û”\",\n    \"33. Ø¢Ù¾ Ú©Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ú©Ú¾Ø§Ù†Ø§ Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ø¨Ø±ÛŒØ§Ù†ÛŒ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"34. Ø¢Ù¾ Ú©Ø³ Ø³Û’ Ù…Ù„Û’ØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ø³Û’ Ù…Ù„Ø§ ØªÚ¾Ø§Û”\",\n    \"35. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø³ÛŒÚ©Ú¾Ø§ØŸ | Ù…ÛŒÚº Ù†Û’ Ù†ÛŒØ§ ÛÙ†Ø± Ø³ÛŒÚ©Ú¾Ø§Û”\",\n    \"36. Ø¢Ù¾ Ú©Ø¨ ØªÚ© ÙˆØ§Ù¾Ø³ Ø¢Ø¦ÛŒÚº Ú¯Û’ØŸ | Ù…ÛŒÚº Ø¯Ùˆ Ú¯Ú¾Ù†Ù¹Û’ Ù…ÛŒÚº ÙˆØ§Ù¾Ø³ Ø¢ Ø¬Ø§Ø¤Úº Ú¯Ø§Û”\",\n    \"37. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ú©ÛÛŒÚº Ø¯ÙˆØ± Ø¬Ø§Ù†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\",\n    \"38. Ø¢Ù¾ Ú©Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ú©Ú¾ÛŒÙ„ Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ú©Ø±Ú©Ù¹ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"39. Ø¢Ù¾ Ù†Û’ Ø§Ø³ Ú©ØªØ§Ø¨ Ú©Ùˆ Ù¾Ú‘Ú¾Ø§ØŸ | Ø¬ÛŒ ÛØ§ÚºØŒ Ù…ÛŒÚº Ù†Û’ ÙˆÛ Ú©ØªØ§Ø¨ Ù¾Ú‘Ú¾ÛŒ ÛÛ’Û”\",\n    \"40. Ø¢Ù¾ Ú©Ùˆ ÛŒÛ Ú†Ù…Ú† Ú†Ø§ÛÛŒÛ’ØŸ | Ù†ÛÛŒÚºØŒ Ù…Ø¬Ú¾Û’ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’Û”\",\n    \"41. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ù¾Ú©Ø§Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"42. Ø¢Ù¾ Ú©Ø§ Ø¨Ú¾Ø§Ø¦ÛŒ Ú©ÛØ§Úº ÛÛ’ØŸ | ÙˆÛ Ø¨Ø§ÛØ± Ú¯ÛŒØ§ ÛÛ’Û”\",\n    \"43. Ø¢Ù¾ Ú©Ùˆ Ú©ÛŒØ§ Ù…Ø¯Ø¯ Ú†Ø§ÛÛŒÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ú©Ú†Ú¾ Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª Ú©ÛŒ Ù…Ø¯Ø¯ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"44. Ø¢Ù¾ Ú©Ø§ Ø¯Ù† Ú©ÛŒØ³Ø§ ØªÚ¾Ø§ØŸ | Ù…ÛŒØ±Ø§ Ø¯Ù† Ø¨ÛØª Ù…ØµØ±ÙˆÙ ØªÚ¾Ø§Û”\",\n    \"45. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºØŸ | Ù…Ø¬Ú¾Û’ Ú©Ú†Ú¾ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ú©Ø±Ù†Ø§ ÛÛ’Û”\",\n    \"46. Ø¢Ù¾ Ú©Ø³ Ú©Û’ Ø³Ø§ØªÚ¾ Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Û’ Ø³Ø§ØªÚ¾ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"47. Ø¢Ù¾ Ú©Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ù…ÙˆØ³Ù… Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ø³Ø±Ø¯ÛŒÙˆÚº Ú©Ø§ Ù…ÙˆØ³Ù… Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"48. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ø®ÛŒØ§Ù„ ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø®ÛŒØ§Ù„ ÛÛ’ Ú©Û ÛÙ…ÛŒÚº ÙÙˆØ±Ø§Ù‹ Ù†Ú©Ù„Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"49. Ø¢Ù¾ Ú©ÛŒØ§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ú©Ú†Ú¾ Ù¾Ø§Ù†ÛŒ Ù¾ÛŒÙ†Ø§ Ú†Ø§ÛØªØ§ ÛÙˆÚºÛ”\",\n    \"50. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø³ÛŒÚ©Ú¾Ø§ØŸ | Ù…ÛŒÚº Ù†Û’ Ú©Ù…Ù¾ÛŒÙˆÙ¹Ø± Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ú©Ú†Ú¾ Ø³ÛŒÚ©Ú¾Ø§Û”\",\n    \"51. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø®Ø±ÛŒØ¯Ø§ØŸ | Ù…ÛŒÚº Ù†Û’ Ú©Ú†Ú¾ Ù¾Ú¾Ù„ Ø®Ø±ÛŒØ¯Û’ ÛÛŒÚºÛ”\",\n    \"52. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ø§Ø±Ø§Ø¯Û ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø§Ø±Ø§Ø¯Û ÛÛ’ Ú©Û Ù…ÛŒÚº Ø¨ÛØª Ø¬Ù„Ø¯ Ø³ÙØ± Ú©Ø±ÙˆÚº Ú¯Ø§Û”\",\n    \"53. Ø¢Ù¾ Ú©Ø³ Ø³Û’ Ø¨Ø§Øª Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ø³Û’ Ø¨Ø§Øª Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"54. Ø¢Ù¾ Ú©ÛØ§Úº Ø³Û’ Ø¢ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ù…Ø§Ø±Ú©ÛŒÙ¹ Ø³Û’ Ø¢ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"55. Ø¢Ù¾ Ù†Û’ Ú©ÛØ§Úº Ø¬Ø§ Ú©Ø± Ú©ÛŒØ§ Ú©ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ú©Ú†Ú¾ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ú©ÛŒÛ”\",\n    \"56. Ø¢Ù¾ Ú©Ùˆ Ú©ÛŒØ§ Ù„Ú¯ØªØ§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ù„Ú¯ØªØ§ ÛÛ’ Ú©Û ÛÙ…ÛŒÚº Ù…Ø²ÛŒØ¯ Ù…Ø­Ù†Øª Ú©Ø±Ù†ÛŒ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"57. Ø¢Ù¾ Ù†Û’ Ú©ÛØ§Úº Ú†Ú¾Ù¹ÛŒØ§Úº Ú¯Ø²Ø§Ø±ÛŒÚºØŸ | Ù…ÛŒÚº Ù†Û’ Ú©ÙˆÛ Ø³Ù„ÛŒÙ…Ø§Ù† Ù…ÛŒÚº Ú†Ú¾Ù¹ÛŒØ§Úº Ú¯Ø²Ø§Ø±ÛŒÚºÛ”\",\n    \"58. Ø¢Ù¾ Ù†Û’ Ú©Ø³ Ø³Û’ Ø¨Ø§Øª Ú©ÛŒØŸ | Ù…ÛŒÚº Ù†Û’ Ø§Ù¾Ù†Û’ Ø³Ø§ØªÚ¾ÛŒ Ø³Û’ Ø¨Ø§Øª Ú©ÛŒÛ”\",\n    \"59. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§Ø¦ÛŒÚº Ú¯Û’ØŸ | Ù…ÛŒÚº ÛŒÙˆÙ†ÛŒÙˆØ±Ø³Ù¹ÛŒ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"60. Ø¢Ù¾ Ú©Ø§ Ø¯Ù† Ú©ÛŒØ³Ø§ Ø±ÛØ§ØŸ | Ø¢Ø¬ Ú©Ø§ Ø¯Ù† Ø§Ú†Ú¾Ø§ ØªÚ¾Ø§Û”\",\n    \"61. Ø¢Ù¾ Ú©Ùˆ Ú©ÛŒØ§ Ø¶Ø±ÙˆØ±Øª ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ú©Ú†Ú¾ Ù¾ÛŒØ³ÙˆÚº Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÛ’Û”\",\n    \"62. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ú©Ú†Ú¾ Ú©Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"63. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ø®ÛŒØ§Ù„ ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø®ÛŒØ§Ù„ ÛÛ’ Ú©Û ÛÙ…ÛŒÚº ÛŒÛ Ù…Ù†ØµÙˆØ¨Û Ø¨Ù†Ø¯ Ú©Ø±Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"64. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø´ÛØ± Ù…ÛŒÚº Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"65. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø±ÛŒÚº Ú¯Û’ØŸ | Ù…ÛŒÚº Ú©Ú†Ú¾ Ú©Ú¾Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¨Ø§ÛØ± Ø¬Ø§Ø¤Úº Ú¯Ø§Û”\",\n    \"66. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ù…Ø´ÙˆØ±Û Ø¯ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ú©ÛØ§ Ú©Û ÛÙ… Ù¾ÛÙ„Û’ Ú©Ø§Ù… Ø®ØªÙ… Ú©Ø±ÛŒÚºÛ”\",\n    \"67. Ø¢Ù¾ Ú©Ø¨ Ø¢Ø¦ÛŒÚº Ú¯Û’ØŸ | Ù…ÛŒÚº 5 Ù…Ù†Ù¹ Ù…ÛŒÚº Ø¢ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"68. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ø§Ø±Ø§Ø¯Û ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø§Ø±Ø§Ø¯Û ÛÛ’ Ú©Û Ù…ÛŒÚº Ø§ÛŒÚ© Ù†ÛŒØ§ Ú©Ø§Ø±ÙˆØ¨Ø§Ø± Ø´Ø±ÙˆØ¹ Ú©Ø±ÙˆÚºÛ”\",\n    \"69. Ø¢Ù¾ Ú©Ø³ Ø³Û’ Ø¨Ø§Øª Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ ÙˆØ§Ù„Ø¯ Ø³Û’ Ø¨Ø§Øª Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"70. Ø¢Ù¾ Ú©ÛØ§Úº Ø³Û’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ù„Ø§ÛÙˆØ± Ø³Û’ ÛÙˆÚºÛ”\",\n    \"71. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø±ÛŒÚº Ú¯Û’ØŸ | Ù…ÛŒÚº Ø³ÙˆÙ†Û’ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"72. Ø¢Ù¾ Ù†Û’ Ú©ÛØ§Úº Ø³ÙØ± Ú©ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ø§Ø³Ù„Ø§Ù… Ø¢Ø¨Ø§Ø¯ Ú©Ø§ Ø³ÙØ± Ú©ÛŒØ§Û”\",\n    \"73. Ø¢Ù¾ Ú©Ø§ Ø¯Ù† Ú©ÛŒØ³Ø§ Ú¯Ø²Ø±Ø§ØŸ | Ù…ÛŒØ±Ø§ Ø¯Ù† Ø¨ÛØª Ø§Ú†Ú¾Ø§ ØªÚ¾Ø§Û”\",\n    \"74. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ù…Ù†ØµÙˆØ¨Û Ø¨Ù†Ø§ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ø¢Ø¬ Ú©Û’ Ù„ÛŒÛ’ Ú†Ú¾Ù¹ÛŒ Ú©Ø§ Ù…Ù†ØµÙˆØ¨Û Ø¨Ù†Ø§ÛŒØ§Û”\",\n    \"75. Ø¢Ù¾ Ú©Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ú©Ú¾Ø§Ù†Ø§ Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ú†Ø§ÙˆÙ„ Ø§ÙˆØ± Ú¯ÙˆØ´Øª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”\",\n    \"76. Ø¢Ù¾ Ú©Ø¨ ØªÚ© Ú©Ø§Ù… Ù¾Ø± Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº 9 Ø¨Ø¬Û’ ØªÚ© Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"77. Ø¢Ù¾ Ú©ÛØ§Úº ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø¯ÙˆØ³Øª Ú©Û’ Ú¯Ú¾Ø± ÛÙˆÚºÛ”\",\n    \"78. Ø¢Ù¾ Ú©Ø§ Ø§Ø±Ø§Ø¯Û Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø§Ø±Ø§Ø¯Û ÛÛ’ Ú©Û Ù…ÛŒÚº ÙˆØ±Ø²Ø´ Ú©Ø±ÙˆÚºÛ”\",\n    \"79. Ø¢Ù¾ Ù†Û’ Ú©ÛØ§Úº Ú†Ú¾Ù¹ÛŒØ§Úº Ú¯Ø²Ø§Ø±ÛŒÚºØŸ | Ù…ÛŒÚº Ù†Û’ Ù†ÛŒÙ„Ù… ÙˆØ§Ø¯ÛŒ Ù…ÛŒÚº Ú†Ú¾Ù¹ÛŒØ§Úº Ú¯Ø²Ø§Ø±ÛŒÚºÛ”\",\n    \"80. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ø®ÛŒØ§Ù„ ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø®ÛŒØ§Ù„ ÛÛ’ Ú©Û ÛÙ…ÛŒÚº Ú©Ø§Ù… Ù¾Ø± Ù…Ø²ÛŒØ¯ Ø¯Ú¾ÛŒØ§Ù† Ø¯ÛŒÙ†Ø§ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"81. Ø¢Ù¾ Ú©Ø¨ ÙˆØ§Ù¾Ø³ Ø¢Ø¦ÛŒÚº Ú¯Û’ØŸ | Ù…ÛŒÚº Ø´Ø§Ù… ØªÚ© ÙˆØ§Ù¾Ø³ Ø¢ Ø¬Ø§Ø¤Úº Ú¯Ø§Û”\",\n    \"82. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ù…Ø´ÙˆØ±Û ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ù…Ø´ÙˆØ±Û ÛÛ’ Ú©Û ØªÙ… Ù¾ÛÙ„Û’ Ø³ÙˆÚ†Ùˆ Ù¾Ú¾Ø± ÙÛŒØµÙ„Û Ú©Ø±ÙˆÛ”\",\n    \"83. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø³ÙˆÚ†Ø§ØŸ | Ù…ÛŒÚº Ù†Û’ Ø³ÙˆÚ†Ø§ Ú©Û ÛÙ…ÛŒÚº Ø§ÙˆØ± Ù…Ø­Ù†Øª Ú©Ø±Ù†ÛŒ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"84. Ø¢Ù¾ Ú©Ø³ Ú©Û’ Ø³Ø§ØªÚ¾ Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø¨Ú¾Ø§Ø¦ÛŒ Ú©Û’ Ø³Ø§ØªÚ¾ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"85. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø³ÛŒÚ©Ú¾Ø§ØŸ | Ù…ÛŒÚº Ù†Û’ Ø®ÙˆØ¯ Ú©Ùˆ Ø¨ÛØªØ± Ø¨Ù†Ø§Ù†Û’ Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ø³ÛŒÚ©Ú¾Ø§Û”\",\n    \"86. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø±Ø§Ø¯Û Ø±Ú©Ú¾ØªÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø¢Ø¬ Ø±Ø§Øª Ú†ÛŒÙ†ÛŒ Ú©Ú¾Ø§Ù†Û’ Ú©Ø§ Ø§Ø±Ø§Ø¯Û Ø±Ú©Ú¾ØªØ§ ÛÙˆÚºÛ”\",\n    \"87. Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ú©Ø§Ù… Ú©Ùˆ Ø®ØªÙ… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"88. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø¯ÙØªØ± Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"89. Ø¢Ù¾ Ú©Ø§ Ø¯Ù† Ú©ÛŒØ³Ø§ ØªÚ¾Ø§ØŸ | Ù…ÛŒØ±Ø§ Ø¯Ù† Ø¨ÛØª Ø§Ú†Ú¾Ø§ ØªÚ¾Ø§Û”\",\n    \"90. Ø¢Ù¾ Ù†Û’ Ú©ÛØ§Úº Ø¬Ø§Ú©Ø± Ú©ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ø¯ÙˆÚ©Ø§Ù† Ø³Û’ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ú©ÛŒÛ”\",\n    \"91. Ø¢Ù¾ Ú©Ø³ Ø³Û’ Ø¨Ø§Øª Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ø§Ù¾Ù†Û’ Ø§Ø³ØªØ§Ø¯ Ø³Û’ Ø¨Ø§Øª Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"92. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ | Ù…ÛŒÚº Ú©Ø§Ù… Ù¾Ø± Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\",\n    \"93. Ø¢Ù¾ Ú©Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ø±Ù†Ú¯ Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û Ø±Ù†Ú¯ Ù†ÛŒÙ„Ø§ ÛÛ’Û”\",\n    \"94. Ø¢Ù¾ Ú©Ø§ Ø§Ø±Ø§Ø¯Û Ú©ÛŒØ§ ÛÛ’ØŸ | Ù…ÛŒØ±Ø§ Ø§Ø±Ø§Ø¯Û ÛÛ’ Ú©Û Ù…ÛŒÚº Ø³ÙØ± Ù¾Ø± Ø¬Ø§Ø¤ÚºÛ”\",\n    \"95. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ú©ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ú©Ú†Ú¾ ÙˆÙ‚Øª Ú¯Ø²Ø§Ø±Ø§Û”\",\n    \"96. Ø¢Ù¾ Ú©Ø§ Ú©ÛŒØ§ Ø®ÛŒØ§Ù„ ÛÛ’ØŸ | Ù…Ø¬Ú¾Û’ Ù„Ú¯ØªØ§ ÛÛ’ Ú©Û ÛÙ…ÛŒÚº ÙÙˆØ±Ø§Ù‹ Ù†Ú©Ù„Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û”\",\n    \"97. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ú©ÛŒØŸ | Ù…ÛŒÚº Ù†Û’ Ú©Ú†Ú¾ Ú©Ù¾Ú‘Û’ Ø®Ø±ÛŒØ¯Û’ ÛÛŒÚºÛ”\",\n    \"98. Ø¢Ù¾ Ú©Ø§ Ø¯Ù† Ú©ÛŒØ³Ø§ ØªÚ¾Ø§ØŸ | Ø¢Ø¬ Ú©Ø§ Ø¯Ù† Ø§Ú†Ú¾Ø§ Ú¯Ø²Ø±Ø§Û”\",\n    \"99. Ø¢Ù¾ Ù†Û’ Ú©ÛØ§Úº Ú†Ú¾Ù¹ÛŒØ§Úº Ú¯Ø²Ø§Ø±ÛŒÚºØŸ | Ù…ÛŒÚº Ù†Û’ Ù…Ø±ÛŒ Ù…ÛŒÚº Ú†Ú¾Ù¹ÛŒØ§Úº Ú¯Ø²Ø§Ø±ÛŒÚºÛ”\",\n    \"100. Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ú©ÛŒØ§ØŸ | Ù…ÛŒÚº Ù†Û’ Ú©Ú†Ú¾ Ù†Ø¦Û’ Ú¯Ø§Ù†Û’ Ø³Ù†Û’Û”\"\n]\n\n\n# File path to the text file\nfile_path = \"/kaggle/input/new-dataset/new.txt\"\n\n# Read the file content\nwith open(file_path, 'r', encoding='utf-8') as file:\n    text_file = file.read()\n\n# Split the file content into lines\nlines = text_file.strip().split(\"\\n\")\n\n# Manually add the conversations\nmerged_lines = text+ lines\n\n# Split each line into question and answer\nquestions = []\nanswers = []\n\nfor line in merged_lines:\n    question, answer = line.split(\"|\")  # Split the line at the delimiter '|'\n    questions.append(question.strip())  # Remove leading/trailing whitespace\n    answers.append(answer.strip())\n\n# Create a DataFrame\ndf = pd.DataFrame({'Question': questions, 'Answer': answers})\n\n# Display the DataFrame\nprint(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:33:35.311714Z","iopub.execute_input":"2024-12-08T16:33:35.312138Z","iopub.status.idle":"2024-12-08T16:33:35.333880Z","shell.execute_reply.started":"2024-12-08T16:33:35.312099Z","shell.execute_reply":"2024-12-08T16:33:35.332563Z"}},"outputs":[{"name":"stdout","text":"                                        Question  \\\n0                                1. Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ   \n1                               2. Ú©ØªÙ†Û’ Ø¨Ø¬Û’ ÛÛŒÚºØŸ   \n2                         3. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ   \n3                       4. Ø¢Ø¬ Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ   \n4                     5. Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ú©Ø§ÙÛŒ Ù¾Ø³Ù†Ø¯ ÛÛ’ØŸ   \n..                                           ...   \n172                      Ø³Ø±Ø® Ø®Ù„ÛŒÛ’ Ú©ÛØ§Úº Ø¨Ù†ØªÛ’ ÛÛŒÚºØŸ   \n173        Ø§Ù†Ø³Ø§Ù† Ú©Û’ Ø¬Ø³Ù… Ù…ÛŒÚº Ú©ØªÙ†ÛŒ ÛÚˆÛŒØ§Úº ÛÙˆØªÛŒ ÛÛŒÚºØŸ   \n174  Ø§Ù†Ø³Ø§Ù†ÛŒ Ø¯Ù…Ø§Øº Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø¨Ú‘Ø§ Ø­ØµÛ Ú©ÙˆÙ†Ø³Ø§ ÛÙˆØªØ§ ÛÛ’ØŸ   \n175       ÛÚˆÛŒ Ø§ÙˆØ± Ø¯Ø§Ù†Øª Ú©Ø³ Ú†ÛŒØ² Ø³Û’ Ù…Ù„ Ú©Ø± Ø¨Ù†ØªÛ’ ÛÛŒÚºØŸ   \n176      ÛÙ…ÙˆÚ¯Ù„ÙˆØ¨ÛŒÙ† Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø§ÛÙ… Ø±Ú©Ù† Ú©ÛŒØ§ ÛÙˆØªØ§ ÛÛ’ØŸ   \n\n                                                Answer  \n0                                 Ù…ÛŒÚº Ù¹Ú¾ÛŒÚ© ÛÙˆÚºØŒ Ø´Ú©Ø±ÛŒÛ!  \n1                                         ØªÛŒÙ† Ø¨Ø¬Û’ ÛÛŒÚºÛ”  \n2                               Ù…ÛŒÚº Ù…Ø§Ø±Ú©ÛŒÙ¹ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”  \n3                           Ø¢Ø¬ Ú¯Ú¾Ø± Ù¾Ø± Ø¢Ø±Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”  \n4                            Ø¬ÛŒ ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”  \n..                                                 ...  \n172                         Ø³Ø±Ø® Ø®Ù„ÛŒÛ’ ÛÚˆÛŒ Ù…ÛŒÚº Ø¨Ù†ØªÛ’ ÛÛŒÚºÛ”  \n173          Ø§Ù†Ø³Ø§Ù† Ú©Û’ Ø¬Ø³Ù… Ù…ÛŒÚº Ø¯Ùˆ Ø³Ùˆ Ú†Ú¾ ÛÚˆÛŒØ§Úº ÛÙˆØªÛŒ ÛÛŒÚºÛ”  \n174        Ø§Ù†Ø³Ø§Ù†ÛŒ Ø¯Ù…Ø§Øº Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø¨Ú‘Ø§ Ø­ØµÛ Ø³Ø±Ø¨Ø±Ù… ÛÙˆØªØ§ ÛÛ’Û”  \n175  ÛÚˆÛŒ Ø§ÙˆØ± Ø¯Ø§Ù†Øª Ú©ÛŒÙ„Ø´ÛŒÙ… Ø§ÙˆØ± ÙØ§Ø³ÙÛŒÙ¹ Ø³Û’ Ù…Ù„ Ú©Ø± Ø¨Ù†ØªÛ’ ÛÛŒÚºÛ”  \n176           ÛÙ…ÙˆÚ¯Ù„ÙˆØ¨ÛŒÙ† Ú©Ø§ Ø³Ø¨ Ø³Û’ Ø§ÛÙ… Ø±Ú©Ù† Ø¢Ø¦Ø±Ù† ÛÙˆØªØ§ ÛÛ’Û”  \n\n[177 rows x 2 columns]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"lengths = df\nlengths[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:48:14.399313Z","iopub.execute_input":"2024-12-08T16:48:14.399720Z","iopub.status.idle":"2024-12-08T16:48:14.411540Z","shell.execute_reply.started":"2024-12-08T16:48:14.399680Z","shell.execute_reply":"2024-12-08T16:48:14.410440Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                     Question                      Answer\n0             1. Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ        Ù…ÛŒÚº Ù¹Ú¾ÛŒÚ© ÛÙˆÚºØŒ Ø´Ú©Ø±ÛŒÛ!\n1            2. Ú©ØªÙ†Û’ Ø¨Ø¬Û’ ÛÛŒÚºØŸ                ØªÛŒÙ† Ø¨Ø¬Û’ ÛÛŒÚºÛ”\n2      3. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ      Ù…ÛŒÚº Ù…Ø§Ø±Ú©ÛŒÙ¹ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”\n3    4. Ø¢Ø¬ Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ  Ø¢Ø¬ Ú¯Ú¾Ø± Ù¾Ø± Ø¢Ø±Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”\n4  5. Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ú©Ø§ÙÛŒ Ù¾Ø³Ù†Ø¯ ÛÛ’ØŸ   Ø¬ÛŒ ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ</td>\n      <td>Ù…ÛŒÚº Ù¹Ú¾ÛŒÚ© ÛÙˆÚºØŒ Ø´Ú©Ø±ÛŒÛ!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2. Ú©ØªÙ†Û’ Ø¨Ø¬Û’ ÛÛŒÚºØŸ</td>\n      <td>ØªÛŒÙ† Ø¨Ø¬Û’ ÛÛŒÚºÛ”</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3. Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ</td>\n      <td>Ù…ÛŒÚº Ù…Ø§Ø±Ú©ÛŒÙ¹ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚºÛ”</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4. Ø¢Ø¬ Ø¢Ù¾ Ú©ÛŒØ§ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚºØŸ</td>\n      <td>Ø¢Ø¬ Ú¯Ú¾Ø± Ù¾Ø± Ø¢Ø±Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5. Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ú©Ø§ÙÛŒ Ù¾Ø³Ù†Ø¯ ÛÛ’ØŸ</td>\n      <td>Ø¬ÛŒ ÛØ§ÚºØŒ Ù…Ø¬Ú¾Û’ Ø¨ÛØª Ù¾Ø³Ù†Ø¯ ÛÛ’Û”</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"lengths.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:36:03.326385Z","iopub.execute_input":"2024-12-08T16:36:03.326753Z","iopub.status.idle":"2024-12-08T16:36:03.349485Z","shell.execute_reply.started":"2024-12-08T16:36:03.326720Z","shell.execute_reply":"2024-12-08T16:36:03.348264Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"               Question                 Answer\ncount               177                    177\nunique              177                    176\ntop     1. Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ  Ù…ÛŒØ±Ø§ Ø¯Ù† Ø¨ÛØª Ø§Ú†Ú¾Ø§ ØªÚ¾Ø§Û”\nfreq                  1                      2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>177</td>\n      <td>177</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>177</td>\n      <td>176</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>1. Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ</td>\n      <td>Ù…ÛŒØ±Ø§ Ø¯Ù† Ø¨ÛØª Ø§Ú†Ú¾Ø§ ØªÚ¾Ø§Û”</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Remove questions and answers that are shorter than 2 words and longer than 20 words.\nmin_line_length = 2\nmax_line_length = 20\n\n# Filter out the questions that are too short/long\nshort_questions_temp = []\nshort_answers_temp = []\n\ni = 0\nfor question in questions:\n    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n        short_questions_temp.append(question)\n        short_answers_temp.append(answers[i])\n    i += 1\n\n# Filter out the answers that are too short/long\nshort_questions = []\nshort_answers = []\n\ni = 0\nfor answer in short_answers_temp:\n    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n        short_answers.append(answer)\n        short_questions.append(short_questions_temp[i])\n    i += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:36:52.049773Z","iopub.execute_input":"2024-12-08T16:36:52.050157Z","iopub.status.idle":"2024-12-08T16:36:52.058547Z","shell.execute_reply.started":"2024-12-08T16:36:52.050121Z","shell.execute_reply":"2024-12-08T16:36:52.057264Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(\"# of questions:\", len(short_questions))\nprint(\"# of answers:\", len(short_answers))\nprint(\"% of data used: {}%\".format(round(len(short_questions)/len(questions),4)*100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:05.048144Z","iopub.execute_input":"2024-12-08T16:37:05.048621Z","iopub.status.idle":"2024-12-08T16:37:05.054899Z","shell.execute_reply.started":"2024-12-08T16:37:05.048584Z","shell.execute_reply":"2024-12-08T16:37:05.053666Z"}},"outputs":[{"name":"stdout","text":"# of questions: 177\n# of answers: 177\n% of data used: 100.0%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"vocab = {}\nfor question in short_questions:\n    for word in question.split():\n        if word not in vocab:\n            vocab[word] = 1\n        else:\n            vocab[word] += 1\n            \nfor answer in short_answers:\n    for word in answer.split():\n        if word not in vocab:\n            vocab[word] = 1\n        else:\n            vocab[word] += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:23.987594Z","iopub.execute_input":"2024-12-08T16:37:23.988210Z","iopub.status.idle":"2024-12-08T16:37:23.997464Z","shell.execute_reply.started":"2024-12-08T16:37:23.988136Z","shell.execute_reply":"2024-12-08T16:37:23.996445Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"threshold = 10\ncount = 0\nfor k,v in vocab.items():\n    if v >= threshold:\n        count += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:36.716906Z","iopub.execute_input":"2024-12-08T16:37:36.717442Z","iopub.status.idle":"2024-12-08T16:37:36.722932Z","shell.execute_reply.started":"2024-12-08T16:37:36.717392Z","shell.execute_reply":"2024-12-08T16:37:36.721665Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Size of total vocab:\", len(vocab))\nprint(\"Size of vocab we will use:\", count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:49.146598Z","iopub.execute_input":"2024-12-08T16:37:49.147003Z","iopub.status.idle":"2024-12-08T16:37:49.153814Z","shell.execute_reply.started":"2024-12-08T16:37:49.146967Z","shell.execute_reply":"2024-12-08T16:37:49.152480Z"}},"outputs":[{"name":"stdout","text":"Size of total vocab: 718\nSize of vocab we will use: 49\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# In case we want to use a different vocabulary sizes for the source and target text, \n# we can set different threshold values.\n# Nonetheless, we will create dictionaries to provide a unique integer for each word.\nquestions_vocab_to_int = {}\n\nword_num = 0\nfor word, count in vocab.items():\n    if count >= threshold:\n        questions_vocab_to_int[word] = word_num\n        word_num += 1\n        \nanswers_vocab_to_int = {}\n\nword_num = 0\nfor word, count in vocab.items():\n    if count >= threshold:\n        answers_vocab_to_int[word] = word_num\n        word_num += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:12.001538Z","iopub.execute_input":"2024-12-08T16:38:12.001899Z","iopub.status.idle":"2024-12-08T16:38:12.009092Z","shell.execute_reply.started":"2024-12-08T16:38:12.001863Z","shell.execute_reply":"2024-12-08T16:38:12.007935Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Add the unique tokens to the vocabulary dictionaries.\ncodes = ['<PAD>','<EOS>','<UNK>','<GO>']\n\nfor code in codes:\n    questions_vocab_to_int[code] = len(questions_vocab_to_int)+1\n    \nfor code in codes:\n    answers_vocab_to_int[code] = len(answers_vocab_to_int)+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:26.251872Z","iopub.execute_input":"2024-12-08T16:38:26.252276Z","iopub.status.idle":"2024-12-08T16:38:26.257886Z","shell.execute_reply.started":"2024-12-08T16:38:26.252241Z","shell.execute_reply":"2024-12-08T16:38:26.256792Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Create dictionaries to map the unique integers to their respective words.\n# i.e. an inverse dictionary for vocab_to_int.\nquestions_int_to_vocab = {v_i: v for v, v_i in questions_vocab_to_int.items()}\nanswers_int_to_vocab = {v_i: v for v, v_i in answers_vocab_to_int.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:38.803120Z","iopub.execute_input":"2024-12-08T16:38:38.803630Z","iopub.status.idle":"2024-12-08T16:38:38.810141Z","shell.execute_reply.started":"2024-12-08T16:38:38.803579Z","shell.execute_reply":"2024-12-08T16:38:38.808885Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Check the length of the dictionaries.\nprint(len(questions_vocab_to_int))\nprint(len(questions_int_to_vocab))\nprint(len(answers_vocab_to_int))\nprint(len(answers_int_to_vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:46.189872Z","iopub.execute_input":"2024-12-08T16:38:46.190244Z","iopub.status.idle":"2024-12-08T16:38:46.196337Z","shell.execute_reply.started":"2024-12-08T16:38:46.190210Z","shell.execute_reply":"2024-12-08T16:38:46.194972Z"}},"outputs":[{"name":"stdout","text":"53\n53\n53\n53\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Add the end of sentence token to the end of every answer.\nfor i in range(len(short_answers)):\n    short_answers[i] += ' <EOS>'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:01.766782Z","iopub.execute_input":"2024-12-08T16:39:01.767169Z","iopub.status.idle":"2024-12-08T16:39:01.772130Z","shell.execute_reply.started":"2024-12-08T16:39:01.767131Z","shell.execute_reply":"2024-12-08T16:39:01.771102Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"questions_int = []\nfor question in short_questions:\n    ints = []\n    for word in question.split():\n        if word not in questions_vocab_to_int:\n            ints.append(questions_vocab_to_int['<UNK>'])\n        else:\n            ints.append(questions_vocab_to_int[word])\n    questions_int.append(ints)\n    \nanswers_int = []\nfor answer in short_answers:\n    ints = []\n    for word in answer.split():\n        if word not in answers_vocab_to_int:\n            ints.append(answers_vocab_to_int['<UNK>'])\n        else:\n            ints.append(answers_vocab_to_int[word])\n    answers_int.append(ints)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:18.509027Z","iopub.execute_input":"2024-12-08T16:39:18.509415Z","iopub.status.idle":"2024-12-08T16:39:18.517471Z","shell.execute_reply.started":"2024-12-08T16:39:18.509378Z","shell.execute_reply":"2024-12-08T16:39:18.515940Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(len(questions_int))\nprint(len(answers_int))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:28.228975Z","iopub.execute_input":"2024-12-08T16:39:28.229345Z","iopub.status.idle":"2024-12-08T16:39:28.235511Z","shell.execute_reply.started":"2024-12-08T16:39:28.229311Z","shell.execute_reply":"2024-12-08T16:39:28.234107Z"}},"outputs":[{"name":"stdout","text":"177\n177\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"word_count = 0\nunk_count = 0\n\nfor question in questions_int:\n    for word in question:\n        if word == questions_vocab_to_int[\"<UNK>\"]:\n            unk_count += 1\n        word_count += 1\n    \nfor answer in answers_int:\n    for word in answer:\n        if word == answers_vocab_to_int[\"<UNK>\"]:\n            unk_count += 1\n        word_count += 1\n    \nunk_ratio = round(unk_count/word_count,4)*100\n    \nprint(\"Total number of words:\", word_count)\nprint(\"Number of times <UNK> is used:\", unk_count)\nprint(\"Percent of words that are <UNK>: {}%\".format(round(unk_ratio,3)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:42.356331Z","iopub.execute_input":"2024-12-08T16:39:42.356846Z","iopub.status.idle":"2024-12-08T16:39:42.368918Z","shell.execute_reply.started":"2024-12-08T16:39:42.356798Z","shell.execute_reply":"2024-12-08T16:39:42.367279Z"}},"outputs":[{"name":"stdout","text":"Total number of words: 2864\nNumber of times <UNK> is used: 1330\nPercent of words that are <UNK>: 46.44%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\nsorted_questions = []\nsorted_answers = []\n\nfor length in range(1, max_line_length+1):\n    for i in enumerate(questions_int):\n        if len(i[1]) == length:\n            sorted_questions.append(questions_int[i[0]])\n            sorted_answers.append(answers_int[i[0]])\n\nprint(len(sorted_questions))\nprint(len(sorted_answers))\nprint()\nfor i in range(3):\n    print(sorted_questions[i])\n    print(sorted_answers[i])\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:58.189138Z","iopub.execute_input":"2024-12-08T16:39:58.189584Z","iopub.status.idle":"2024-12-08T16:39:58.197752Z","shell.execute_reply.started":"2024-12-08T16:39:58.189541Z","shell.execute_reply":"2024-12-08T16:39:58.196466Z"}},"outputs":[{"name":"stdout","text":"177\n177\n\n[52, 6, 10]\n[52, 31, 52, 45, 51]\n\n[52, 52, 10]\n[52, 52, 20, 34, 52, 52, 45, 51]\n\n[52, 0, 52, 1]\n[15, 52, 52, 52, 51]\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"pip install transformers datasets torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:50:00.611885Z","iopub.execute_input":"2024-12-08T16:50:00.612639Z","iopub.status.idle":"2024-12-08T16:50:12.953530Z","shell.execute_reply.started":"2024-12-08T16:50:00.612531Z","shell.execute_reply":"2024-12-08T16:50:12.951932Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:50:39.820659Z","iopub.execute_input":"2024-12-08T16:50:39.821219Z","iopub.status.idle":"2024-12-08T16:50:40.877282Z","shell.execute_reply.started":"2024-12-08T16:50:39.821145Z","shell.execute_reply":"2024-12-08T16:50:40.875812Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"dataset_list = lengths.to_dict(orient='records')\n\n# Create a Hugging Face Dataset\ndataset = Dataset.from_list(dataset_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:51:31.392423Z","iopub.execute_input":"2024-12-08T16:51:31.393350Z","iopub.status.idle":"2024-12-08T16:51:31.452075Z","shell.execute_reply.started":"2024-12-08T16:51:31.393283Z","shell.execute_reply":"2024-12-08T16:51:31.450512Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:52:29.208228Z","iopub.execute_input":"2024-12-08T16:52:29.208621Z","iopub.status.idle":"2024-12-08T16:52:29.215800Z","shell.execute_reply.started":"2024-12-08T16:52:29.208587Z","shell.execute_reply":"2024-12-08T16:52:29.214580Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Answer'],\n    num_rows: 177\n})"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\n# Load the GPT2 tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\n# Set the padding token to eos_token\ntokenizer.pad_token = tokenizer.eos_token\n\n# Tokenize the 'Question' and 'Answer' columns\ndef tokenize_function(examples):\n    # Tokenize input and output\n    inputs = tokenizer(examples['Question'], padding=\"max_length\", truncation=True, max_length=128)\n    outputs = tokenizer(examples['Answer'], padding=\"max_length\", truncation=True, max_length=128)\n    return {'input_ids': inputs['input_ids'], 'labels': outputs['input_ids']}\n\n# Apply tokenization to the dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:54:19.870249Z","iopub.execute_input":"2024-12-08T16:54:19.870660Z","iopub.status.idle":"2024-12-08T16:54:21.769074Z","shell.execute_reply.started":"2024-12-08T16:54:19.870622Z","shell.execute_reply":"2024-12-08T16:54:21.767671Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/177 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d076becf51c84b3d92b133256974f684"}},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel\n\n# Load the pre-trained GPT2 model\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:54:46.316781Z","iopub.execute_input":"2024-12-08T16:54:46.317199Z","iopub.status.idle":"2024-12-08T16:54:51.869474Z","shell.execute_reply.started":"2024-12-08T16:54:46.317142Z","shell.execute_reply":"2024-12-08T16:54:51.868281Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08000b34b53b44f1b3ecc2dd07e4e4fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04097c2a56e745a3a6765017b0b89fb1"}},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',  # Output directory for the model\n    evaluation_strategy=\"epoch\",  # Evaluate every epoch\n    learning_rate=5e-5,\n    per_device_train_batch_size=8,  # Batch size\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,  # Number of epochs\n    weight_decay=0.01,\n    logging_dir='./logs',  # Logs directory\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_dataset,  # Optionally, you can split the dataset\n)\n\n# Fine-tune the model\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:54:59.985159Z","iopub.execute_input":"2024-12-08T16:54:59.985892Z","iopub.status.idle":"2024-12-08T17:07:58.279884Z","shell.execute_reply.started":"2024-12-08T16:54:59.985852Z","shell.execute_reply":"2024-12-08T17:07:58.278061Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241208_165541-bnju8r16</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/i210319-national-university-of-/huggingface/runs/bnju8r16' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/i210319-national-university-of-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/i210319-national-university-of-/huggingface' target=\"_blank\">https://wandb.ai/i210319-national-university-of-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/i210319-national-university-of-/huggingface/runs/bnju8r16' target=\"_blank\">https://wandb.ai/i210319-national-university-of-/huggingface/runs/bnju8r16</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [69/69 12:05, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.437747</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.342805</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.313356</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=69, training_loss=1.7166374317113904, metrics={'train_runtime': 773.4197, 'train_samples_per_second': 0.687, 'train_steps_per_second': 0.089, 'total_flos': 34686517248000.0, 'train_loss': 1.7166374317113904, 'epoch': 3.0})"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# Generate response using the fine-tuned model\ndef generate_response(input_text):\n    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n    chat_history_ids = model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n    return tokenizer.decode(chat_history_ids[0], skip_special_tokens=True)\n\n# Test the model\nresponse = generate_response(\"Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸ\")\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:09:14.406934Z","iopub.execute_input":"2024-12-08T17:09:14.407443Z","iopub.status.idle":"2024-12-08T17:09:14.833706Z","shell.execute_reply.started":"2024-12-08T17:09:14.407392Z","shell.execute_reply":"2024-12-08T17:09:14.832628Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Ø¢Ù¾ Ú©ÛØ§Úº Ø¬Ø§ Ø±ÛÛ’ ÛÛŒÚºØŸÛÛÛÛ\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\n# Load pre-trained DialoGPT model\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:09:58.575050Z","iopub.execute_input":"2024-12-08T17:09:58.575520Z","iopub.status.idle":"2024-12-08T17:10:05.098679Z","shell.execute_reply.started":"2024-12-08T17:09:58.575473Z","shell.execute_reply":"2024-12-08T17:10:05.097153Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c8e8646ff384768b6404f709af41dac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45aa0cd4a81542e5915beb945528b3ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b064b5ae7e4bd5827bcf5807b3db8b"}},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./dialoggpt_finetuned\",  # output directory\n    evaluation_strategy=\"epoch\",  # Evaluate every epoch\n    learning_rate=5e-5,\n    per_device_train_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\n# Define the trainer\ntrainer = Trainer(\n    model=model,                           # the model to train\n    args=training_args,                    # training arguments\n    train_dataset=tokenized_dataset,  \n    eval_dataset = tokenized_dataset,# training dataset\n    tokenizer=tokenizer,                   # tokenizer\n)\n\n# Start training\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:11:03.434069Z","iopub.execute_input":"2024-12-08T17:11:03.434665Z","iopub.status.idle":"2024-12-08T17:46:52.332287Z","shell.execute_reply.started":"2024-12-08T17:11:03.434600Z","shell.execute_reply":"2024-12-08T17:46:52.330832Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_24/2864353507.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [135/135 35:31, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.517178</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.391605</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.360780</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=135, training_loss=1.6125577573423033, metrics={'train_runtime': 2147.8785, 'train_samples_per_second': 0.247, 'train_steps_per_second': 0.063, 'total_flos': 123285017198592.0, 'train_loss': 1.6125577573423033, 'epoch': 3.0})"},"metadata":{}}],"execution_count":55}]}