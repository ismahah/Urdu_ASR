{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10140477,"sourceType":"datasetVersion","datasetId":6258678}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# File path to the text file\nfile_path = \"/kaggle/input/new-dataset/new.txt\"\ntext = []\n# Read the file content\nwith open(file_path, 'r', encoding='utf-8') as file:\n    text = file.read()\n\n# Split the text into lines (assuming each line contains a question-answer pair)\nlines = text.strip().split(\"\\n\")\n\n# Split each line into question and answer\nquestions = []\nanswers = []\n\nfor line in lines:\n    question, answer = line.split(\"|\")  # Split the line at the delimiter '|'\n    questions.append(question.strip())  # Remove leading/trailing whitespace\n    answers.append(answer.strip())\n\n# Create a DataFrame\ndf = pd.DataFrame({'Question': questions, 'Answer': answers})\n\n# Display the DataFrame\nprint(df)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:28:40.216240Z","iopub.execute_input":"2024-12-08T16:28:40.217222Z","iopub.status.idle":"2024-12-08T16:28:40.246791Z","shell.execute_reply.started":"2024-12-08T16:28:40.217147Z","shell.execute_reply":"2024-12-08T16:28:40.244951Z"}},"outputs":[{"name":"stdout","text":"                                       Question  \\\n0              ﻿سب سے باہر والا سیارہ کونسا ہے؟   \n1        دورھ میں کتنے فیصد پانی پایا جاتا ہے ؟   \n2                     چارج کی یونٹ کیا ھوتی ھے؟   \n3     ہائی فریکوئنسی کی ویو لینتھ کتنی ہوتی ہے؟   \n4   وائٹ من اے کی کمی سے کون سی بیماری ہوتی ہے؟   \n..                                          ...   \n72                      سرخ خلیے کہاں بنتے ہیں؟   \n73        انسان کے جسم میں کتنی ہڈیاں ہوتی ہیں؟   \n74  انسانی دماغ کا سب سے بڑا حصہ کونسا ہوتا ہے؟   \n75       ہڈی اور دانت کس چیز سے مل کر بنتے ہیں؟   \n76      ہموگلوبین کا سب سے اہم رکن کیا ہوتا ہے؟   \n\n                                               Answer  \n0                    سب سے باہر والا سیارہ نیپچون ہے۔  \n1                دودھ میں اسی فیصد پانی پایا جاتا ہے۔  \n2                        چارج کی یونٹ کو لمب ہوتی ہے۔  \n3          ہائی فریکوئنسی کی ویو لینتھ چھوٹی ہوتی ہے۔  \n4   وائٹ من اے کی کمی سےرات کو اندھے پن کی بیماری ...  \n..                                                ...  \n72                         سرخ خلیے ہڈی میں بنتے ہیں۔  \n73          انسان کے جسم میں دو سو چھ ہڈیاں ہوتی ہیں۔  \n74        انسانی دماغ کا سب سے بڑا حصہ سربرم ہوتا ہے۔  \n75  ہڈی اور دانت کیلشیم اور فاسفیٹ سے مل کر بنتے ہیں۔  \n76           ہموگلوبین کا سب سے اہم رکن آئرن ہوتا ہے۔  \n\n[77 rows x 2 columns]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Manually entered conversations\ntext = [\n    \"1. آپ کیسے ہیں؟ | میں ٹھیک ہوں، شکریہ!\",\n    \"2. کتنے بجے ہیں؟ | تین بجے ہیں۔\",\n    \"3. آپ کہاں جا رہے ہیں؟ | میں مارکیٹ جا رہا ہوں۔\",\n    \"4. آج آپ کیا کر رہے ہیں؟ | آج گھر پر آرام کر رہا ہوں۔\",\n    \"5. کیا آپ کو کافی پسند ہے؟ | جی ہاں، مجھے بہت پسند ہے۔\",\n    \"6. آپ کا دن کیسا گزرا؟ | بہت اچھا گزرا، شکریہ!\",\n    \"7. آپ کا پسندیدہ رنگ کون سا ہے؟ | مجھے نیلا رنگ پسند ہے۔\",\n    \"8. آپ کہاں رہتے ہیں؟ | میں لاہور میں رہتا ہوں۔\",\n    \"9. کیا آپ مصروف ہیں؟ | نہیں، میں فارغ ہوں۔\",\n    \"10. رات کا کھانا کیا ہے؟ | آج رات پاستا بن رہا ہے۔\",\n    \"11. آپ کی عمر کتنی ہے؟ | میری عمر 25 سال ہے۔\",\n    \"12. کیا آپ میری مدد کر سکتے ہیں؟ | جی ہاں، آپ کو کس چیز کی مدد چاہیے؟\",\n    \"13. کیا آپ نے کھانا کھایا؟ | جی ہاں، ایک گھنٹہ پہلے لنچ کیا تھا۔\",\n    \"14. آپ کا فون کہاں ہے؟ | وہ ٹیبل پر پڑا ہے۔\",\n    \"15. کیا آپ ٹی وی دیکھتے ہیں؟ | کبھی کبھار، زیادہ تر رات کو۔\",\n    \"16. آپ نے کیا خریدا؟ | میں نے سبزیاں خریدی ہیں۔\",\n    \"17. کیا آپ پارٹی میں آ رہے ہیں؟ | جی ہاں، میں آ رہا ہوں۔\",\n    \"18. آپ کی پسندیدہ فلم کون سی ہے؟ | مجھے 'شاشنک ریڈمپشن' بہت پسند ہے۔\",\n    \"19. کیا آپ آج کام کر رہے ہیں؟ | جی ہاں، مجھے بعد میں میٹنگ ہے۔\",\n    \"20. آپ کے گھر والے کیسے ہیں؟ | وہ سب خیریت سے ہیں، شکریہ!\",\n    \"21. آپ تفریح کے لیے کیا کرتے ہیں؟ | مجھے کتابیں پڑھنا پسند ہے۔\",\n    \"22. کیا میں یہ لے سکتا ہوں؟ | جی ہاں، بالکل لے لیں۔\",\n    \"23. کیا آپ تھکے ہوئے ہیں؟ | ہاں، تھوڑا تھکا ہوا ہوں۔\",\n    \"24. آپ کتنے بجے اٹھتے ہیں؟ | میں صبح 7 بجے اٹھتا ہوں۔\",\n    \"25. آپ کیا کھانا چاہتے ہیں؟ | مجھے پیزا کھانے کا دل چاہ رہا ہے۔\",\n    \"26. کل آپ کہاں گئے تھے؟ | میں پارک گیا تھا۔\",\n    \"27. کیا آپ نے یہ فلم دیکھی ہے؟ | جی ہاں، میں نے پچھلے ہفتے دیکھی تھی۔\",\n    \"28. آج کا موسم کیسا ہے؟ | آج کا موسم دھوپ والا اور گرم ہے۔\",\n    \"29. کیا آپ کو موسیقی پسند ہے؟ | جی ہاں، مجھے موسیقی سننا پسند ہے۔\",\n    \"30. کیا آپ کو چائے پسند ہے؟ | ہاں، مجھے بہت پسند ہے۔\",\n    \"31. آپ کہاں کام کرتے ہیں؟ | میں ایک کمپنی میں کام کرتا ہوں۔\",\n    \"32. آپ کو کب تک آنا ہے؟ | مجھے 10 منٹ میں آنا ہے۔\",\n    \"33. آپ کا پسندیدہ کھانا کیا ہے؟ | مجھے بریانی بہت پسند ہے۔\",\n    \"34. آپ کس سے ملے؟ | میں اپنے دوست سے ملا تھا۔\",\n    \"35. آپ نے کیا سیکھا؟ | میں نے نیا ہنر سیکھا۔\",\n    \"36. آپ کب تک واپس آئیں گے؟ | میں دو گھنٹے میں واپس آ جاؤں گا۔\",\n    \"37. آپ کہاں جانا چاہتے ہیں؟ | میں کہیں دور جانا چاہتا ہوں۔\",\n    \"38. آپ کا پسندیدہ کھیل کیا ہے؟ | مجھے کرکٹ بہت پسند ہے۔\",\n    \"39. آپ نے اس کتاب کو پڑھا؟ | جی ہاں، میں نے وہ کتاب پڑھی ہے۔\",\n    \"40. آپ کو یہ چمچ چاہیے؟ | نہیں، مجھے نہیں چاہیے۔\",\n    \"41. آپ کیا کر رہے ہیں؟ | میں کھانا پکانے کی کوشش کر رہا ہوں۔\",\n    \"42. آپ کا بھائی کہاں ہے؟ | وہ باہر گیا ہے۔\",\n    \"43. آپ کو کیا مدد چاہیے؟ | مجھے کچھ دستاویزات کی مدد چاہیے۔\",\n    \"44. آپ کا دن کیسا تھا؟ | میرا دن بہت مصروف تھا۔\",\n    \"45. آپ کہاں جانا چاہتے ہیں؟ | مجھے کچھ خریداری کرنا ہے۔\",\n    \"46. آپ کس کے ساتھ جا رہے ہیں؟ | میں اپنے دوست کے ساتھ جا رہا ہوں۔\",\n    \"47. آپ کا پسندیدہ موسم کیا ہے؟ | مجھے سردیوں کا موسم بہت پسند ہے۔\",\n    \"48. آپ کا کیا خیال ہے؟ | میرا خیال ہے کہ ہمیں فوراً نکلنا چاہیے۔\",\n    \"49. آپ کیا چاہتے ہیں؟ | میں کچھ پانی پینا چاہتا ہوں۔\",\n    \"50. آپ نے کیا سیکھا؟ | میں نے کمپیوٹر کے بارے میں کچھ سیکھا۔\",\n    \"51. آپ نے کیا خریدا؟ | میں نے کچھ پھل خریدے ہیں۔\",\n    \"52. آپ کا کیا ارادہ ہے؟ | میرا ارادہ ہے کہ میں بہت جلد سفر کروں گا۔\",\n    \"53. آپ کس سے بات کر رہے ہیں؟ | میں اپنے دوست سے بات کر رہا ہوں۔\",\n    \"54. آپ کہاں سے آ رہے ہیں؟ | میں مارکیٹ سے آ رہا ہوں۔\",\n    \"55. آپ نے کہاں جا کر کیا کیا؟ | میں نے کچھ خریداری کی۔\",\n    \"56. آپ کو کیا لگتا ہے؟ | مجھے لگتا ہے کہ ہمیں مزید محنت کرنی چاہیے۔\",\n    \"57. آپ نے کہاں چھٹیاں گزاریں؟ | میں نے کوہ سلیمان میں چھٹیاں گزاریں۔\",\n    \"58. آپ نے کس سے بات کی؟ | میں نے اپنے ساتھی سے بات کی۔\",\n    \"59. آپ کہاں جائیں گے؟ | میں یونیورسٹی جا رہا ہوں۔\",\n    \"60. آپ کا دن کیسا رہا؟ | آج کا دن اچھا تھا۔\",\n    \"61. آپ کو کیا ضرورت ہے؟ | مجھے کچھ پیسوں کی ضرورت ہے۔\",\n    \"62. آپ کیا کر رہے ہیں؟ | میں کچھ کام کر رہا ہوں۔\",\n    \"63. آپ کا کیا خیال ہے؟ | میرا خیال ہے کہ ہمیں یہ منصوبہ بند کرنا چاہیے۔\",\n    \"64. آپ کہاں جا رہے ہیں؟ | میں شہر میں جا رہا ہوں۔\",\n    \"65. آپ کیا کریں گے؟ | میں کچھ کھانے کے لیے باہر جاؤں گا۔\",\n    \"66. آپ نے کیا مشورہ دیا؟ | میں نے کہا کہ ہم پہلے کام ختم کریں۔\",\n    \"67. آپ کب آئیں گے؟ | میں 5 منٹ میں آ رہا ہوں۔\",\n    \"68. آپ کا کیا ارادہ ہے؟ | میرا ارادہ ہے کہ میں ایک نیا کاروبار شروع کروں۔\",\n    \"69. آپ کس سے بات کر رہے ہیں؟ | میں اپنے والد سے بات کر رہا ہوں۔\",\n    \"70. آپ کہاں سے ہیں؟ | میں لاہور سے ہوں۔\",\n    \"71. آپ کیا کریں گے؟ | میں سونے جا رہا ہوں۔\",\n    \"72. آپ نے کہاں سفر کیا؟ | میں نے اسلام آباد کا سفر کیا۔\",\n    \"73. آپ کا دن کیسا گزرا؟ | میرا دن بہت اچھا تھا۔\",\n    \"74. آپ نے کیا منصوبہ بنایا؟ | میں نے آج کے لیے چھٹی کا منصوبہ بنایا۔\",\n    \"75. آپ کا پسندیدہ کھانا کیا ہے؟ | مجھے چاول اور گوشت پسند ہے۔\",\n    \"76. آپ کب تک کام پر جا رہے ہیں؟ | میں 9 بجے تک جا رہا ہوں۔\",\n    \"77. آپ کہاں ہیں؟ | میں اپنے دوست کے گھر ہوں۔\",\n    \"78. آپ کا ارادہ کیا ہے؟ | میرا ارادہ ہے کہ میں ورزش کروں۔\",\n    \"79. آپ نے کہاں چھٹیاں گزاریں؟ | میں نے نیلم وادی میں چھٹیاں گزاریں۔\",\n    \"80. آپ کا کیا خیال ہے؟ | میرا خیال ہے کہ ہمیں کام پر مزید دھیان دینا چاہیے۔\",\n    \"81. آپ کب واپس آئیں گے؟ | میں شام تک واپس آ جاؤں گا۔\",\n    \"82. آپ کا کیا مشورہ ہے؟ | میرا مشورہ ہے کہ تم پہلے سوچو پھر فیصلہ کرو۔\",\n    \"83. آپ نے کیا سوچا؟ | میں نے سوچا کہ ہمیں اور محنت کرنی چاہیے۔\",\n    \"84. آپ کس کے ساتھ جا رہے ہیں؟ | میں اپنے بھائی کے ساتھ جا رہا ہوں۔\",\n    \"85. آپ نے کیا سیکھا؟ | میں نے خود کو بہتر بنانے کے بارے میں سیکھا۔\",\n    \"86. آپ کیا کھانے کا ارادہ رکھتے ہیں؟ | میں آج رات چینی کھانے کا ارادہ رکھتا ہوں۔\",\n    \"87. آپ کیا کر رہے ہیں؟ | میں اپنے کام کو ختم کر رہا ہوں۔\",\n    \"88. آپ کہاں جا رہے ہیں؟ | میں اپنے دفتر جا رہا ہوں۔\",\n    \"89. آپ کا دن کیسا تھا؟ | میرا دن بہت اچھا تھا۔\",\n    \"90. آپ نے کہاں جاکر کیا؟ | میں نے دوکان سے خریداری کی۔\",\n    \"91. آپ کس سے بات کر رہے ہیں؟ | میں اپنے استاد سے بات کر رہا ہوں۔\",\n    \"92. آپ کہاں جا رہے ہیں؟ | میں کام پر جا رہا ہوں۔\",\n    \"93. آپ کا پسندیدہ رنگ کیا ہے؟ | میرا پسندیدہ رنگ نیلا ہے۔\",\n    \"94. آپ کا ارادہ کیا ہے؟ | میرا ارادہ ہے کہ میں سفر پر جاؤں۔\",\n    \"95. آپ نے کیا کیا؟ | میں نے کچھ وقت گزارا۔\",\n    \"96. آپ کا کیا خیال ہے؟ | مجھے لگتا ہے کہ ہمیں فوراً نکلنا چاہیے۔\",\n    \"97. آپ نے کیا خریداری کی؟ | میں نے کچھ کپڑے خریدے ہیں۔\",\n    \"98. آپ کا دن کیسا تھا؟ | آج کا دن اچھا گزرا۔\",\n    \"99. آپ نے کہاں چھٹیاں گزاریں؟ | میں نے مری میں چھٹیاں گزاریں۔\",\n    \"100. آپ نے کیا کیا؟ | میں نے کچھ نئے گانے سنے۔\"\n]\n\n\n# File path to the text file\nfile_path = \"/kaggle/input/new-dataset/new.txt\"\n\n# Read the file content\nwith open(file_path, 'r', encoding='utf-8') as file:\n    text_file = file.read()\n\n# Split the file content into lines\nlines = text_file.strip().split(\"\\n\")\n\n# Manually add the conversations\nmerged_lines = text+ lines\n\n# Split each line into question and answer\nquestions = []\nanswers = []\n\nfor line in merged_lines:\n    question, answer = line.split(\"|\")  # Split the line at the delimiter '|'\n    questions.append(question.strip())  # Remove leading/trailing whitespace\n    answers.append(answer.strip())\n\n# Create a DataFrame\ndf = pd.DataFrame({'Question': questions, 'Answer': answers})\n\n# Display the DataFrame\nprint(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:33:35.311714Z","iopub.execute_input":"2024-12-08T16:33:35.312138Z","iopub.status.idle":"2024-12-08T16:33:35.333880Z","shell.execute_reply.started":"2024-12-08T16:33:35.312099Z","shell.execute_reply":"2024-12-08T16:33:35.332563Z"}},"outputs":[{"name":"stdout","text":"                                        Question  \\\n0                                1. آپ کیسے ہیں؟   \n1                               2. کتنے بجے ہیں؟   \n2                         3. آپ کہاں جا رہے ہیں؟   \n3                       4. آج آپ کیا کر رہے ہیں؟   \n4                     5. کیا آپ کو کافی پسند ہے؟   \n..                                           ...   \n172                      سرخ خلیے کہاں بنتے ہیں؟   \n173        انسان کے جسم میں کتنی ہڈیاں ہوتی ہیں؟   \n174  انسانی دماغ کا سب سے بڑا حصہ کونسا ہوتا ہے؟   \n175       ہڈی اور دانت کس چیز سے مل کر بنتے ہیں؟   \n176      ہموگلوبین کا سب سے اہم رکن کیا ہوتا ہے؟   \n\n                                                Answer  \n0                                 میں ٹھیک ہوں، شکریہ!  \n1                                         تین بجے ہیں۔  \n2                               میں مارکیٹ جا رہا ہوں۔  \n3                           آج گھر پر آرام کر رہا ہوں۔  \n4                            جی ہاں، مجھے بہت پسند ہے۔  \n..                                                 ...  \n172                         سرخ خلیے ہڈی میں بنتے ہیں۔  \n173          انسان کے جسم میں دو سو چھ ہڈیاں ہوتی ہیں۔  \n174        انسانی دماغ کا سب سے بڑا حصہ سربرم ہوتا ہے۔  \n175  ہڈی اور دانت کیلشیم اور فاسفیٹ سے مل کر بنتے ہیں۔  \n176           ہموگلوبین کا سب سے اہم رکن آئرن ہوتا ہے۔  \n\n[177 rows x 2 columns]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"lengths = df\nlengths[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:48:14.399313Z","iopub.execute_input":"2024-12-08T16:48:14.399720Z","iopub.status.idle":"2024-12-08T16:48:14.411540Z","shell.execute_reply.started":"2024-12-08T16:48:14.399680Z","shell.execute_reply":"2024-12-08T16:48:14.410440Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                     Question                      Answer\n0             1. آپ کیسے ہیں؟        میں ٹھیک ہوں، شکریہ!\n1            2. کتنے بجے ہیں؟                تین بجے ہیں۔\n2      3. آپ کہاں جا رہے ہیں؟      میں مارکیٹ جا رہا ہوں۔\n3    4. آج آپ کیا کر رہے ہیں؟  آج گھر پر آرام کر رہا ہوں۔\n4  5. کیا آپ کو کافی پسند ہے؟   جی ہاں، مجھے بہت پسند ہے۔","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. آپ کیسے ہیں؟</td>\n      <td>میں ٹھیک ہوں، شکریہ!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2. کتنے بجے ہیں؟</td>\n      <td>تین بجے ہیں۔</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3. آپ کہاں جا رہے ہیں؟</td>\n      <td>میں مارکیٹ جا رہا ہوں۔</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4. آج آپ کیا کر رہے ہیں؟</td>\n      <td>آج گھر پر آرام کر رہا ہوں۔</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5. کیا آپ کو کافی پسند ہے؟</td>\n      <td>جی ہاں، مجھے بہت پسند ہے۔</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"lengths.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:36:03.326385Z","iopub.execute_input":"2024-12-08T16:36:03.326753Z","iopub.status.idle":"2024-12-08T16:36:03.349485Z","shell.execute_reply.started":"2024-12-08T16:36:03.326720Z","shell.execute_reply":"2024-12-08T16:36:03.348264Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"               Question                 Answer\ncount               177                    177\nunique              177                    176\ntop     1. آپ کیسے ہیں؟  میرا دن بہت اچھا تھا۔\nfreq                  1                      2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>177</td>\n      <td>177</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>177</td>\n      <td>176</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>1. آپ کیسے ہیں؟</td>\n      <td>میرا دن بہت اچھا تھا۔</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Remove questions and answers that are shorter than 2 words and longer than 20 words.\nmin_line_length = 2\nmax_line_length = 20\n\n# Filter out the questions that are too short/long\nshort_questions_temp = []\nshort_answers_temp = []\n\ni = 0\nfor question in questions:\n    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n        short_questions_temp.append(question)\n        short_answers_temp.append(answers[i])\n    i += 1\n\n# Filter out the answers that are too short/long\nshort_questions = []\nshort_answers = []\n\ni = 0\nfor answer in short_answers_temp:\n    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n        short_answers.append(answer)\n        short_questions.append(short_questions_temp[i])\n    i += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:36:52.049773Z","iopub.execute_input":"2024-12-08T16:36:52.050157Z","iopub.status.idle":"2024-12-08T16:36:52.058547Z","shell.execute_reply.started":"2024-12-08T16:36:52.050121Z","shell.execute_reply":"2024-12-08T16:36:52.057264Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(\"# of questions:\", len(short_questions))\nprint(\"# of answers:\", len(short_answers))\nprint(\"% of data used: {}%\".format(round(len(short_questions)/len(questions),4)*100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:05.048144Z","iopub.execute_input":"2024-12-08T16:37:05.048621Z","iopub.status.idle":"2024-12-08T16:37:05.054899Z","shell.execute_reply.started":"2024-12-08T16:37:05.048584Z","shell.execute_reply":"2024-12-08T16:37:05.053666Z"}},"outputs":[{"name":"stdout","text":"# of questions: 177\n# of answers: 177\n% of data used: 100.0%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"vocab = {}\nfor question in short_questions:\n    for word in question.split():\n        if word not in vocab:\n            vocab[word] = 1\n        else:\n            vocab[word] += 1\n            \nfor answer in short_answers:\n    for word in answer.split():\n        if word not in vocab:\n            vocab[word] = 1\n        else:\n            vocab[word] += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:23.987594Z","iopub.execute_input":"2024-12-08T16:37:23.988210Z","iopub.status.idle":"2024-12-08T16:37:23.997464Z","shell.execute_reply.started":"2024-12-08T16:37:23.988136Z","shell.execute_reply":"2024-12-08T16:37:23.996445Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"threshold = 10\ncount = 0\nfor k,v in vocab.items():\n    if v >= threshold:\n        count += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:36.716906Z","iopub.execute_input":"2024-12-08T16:37:36.717442Z","iopub.status.idle":"2024-12-08T16:37:36.722932Z","shell.execute_reply.started":"2024-12-08T16:37:36.717392Z","shell.execute_reply":"2024-12-08T16:37:36.721665Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"Size of total vocab:\", len(vocab))\nprint(\"Size of vocab we will use:\", count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:37:49.146598Z","iopub.execute_input":"2024-12-08T16:37:49.147003Z","iopub.status.idle":"2024-12-08T16:37:49.153814Z","shell.execute_reply.started":"2024-12-08T16:37:49.146967Z","shell.execute_reply":"2024-12-08T16:37:49.152480Z"}},"outputs":[{"name":"stdout","text":"Size of total vocab: 718\nSize of vocab we will use: 49\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# In case we want to use a different vocabulary sizes for the source and target text, \n# we can set different threshold values.\n# Nonetheless, we will create dictionaries to provide a unique integer for each word.\nquestions_vocab_to_int = {}\n\nword_num = 0\nfor word, count in vocab.items():\n    if count >= threshold:\n        questions_vocab_to_int[word] = word_num\n        word_num += 1\n        \nanswers_vocab_to_int = {}\n\nword_num = 0\nfor word, count in vocab.items():\n    if count >= threshold:\n        answers_vocab_to_int[word] = word_num\n        word_num += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:12.001538Z","iopub.execute_input":"2024-12-08T16:38:12.001899Z","iopub.status.idle":"2024-12-08T16:38:12.009092Z","shell.execute_reply.started":"2024-12-08T16:38:12.001863Z","shell.execute_reply":"2024-12-08T16:38:12.007935Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Add the unique tokens to the vocabulary dictionaries.\ncodes = ['<PAD>','<EOS>','<UNK>','<GO>']\n\nfor code in codes:\n    questions_vocab_to_int[code] = len(questions_vocab_to_int)+1\n    \nfor code in codes:\n    answers_vocab_to_int[code] = len(answers_vocab_to_int)+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:26.251872Z","iopub.execute_input":"2024-12-08T16:38:26.252276Z","iopub.status.idle":"2024-12-08T16:38:26.257886Z","shell.execute_reply.started":"2024-12-08T16:38:26.252241Z","shell.execute_reply":"2024-12-08T16:38:26.256792Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Create dictionaries to map the unique integers to their respective words.\n# i.e. an inverse dictionary for vocab_to_int.\nquestions_int_to_vocab = {v_i: v for v, v_i in questions_vocab_to_int.items()}\nanswers_int_to_vocab = {v_i: v for v, v_i in answers_vocab_to_int.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:38.803120Z","iopub.execute_input":"2024-12-08T16:38:38.803630Z","iopub.status.idle":"2024-12-08T16:38:38.810141Z","shell.execute_reply.started":"2024-12-08T16:38:38.803579Z","shell.execute_reply":"2024-12-08T16:38:38.808885Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Check the length of the dictionaries.\nprint(len(questions_vocab_to_int))\nprint(len(questions_int_to_vocab))\nprint(len(answers_vocab_to_int))\nprint(len(answers_int_to_vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:38:46.189872Z","iopub.execute_input":"2024-12-08T16:38:46.190244Z","iopub.status.idle":"2024-12-08T16:38:46.196337Z","shell.execute_reply.started":"2024-12-08T16:38:46.190210Z","shell.execute_reply":"2024-12-08T16:38:46.194972Z"}},"outputs":[{"name":"stdout","text":"53\n53\n53\n53\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Add the end of sentence token to the end of every answer.\nfor i in range(len(short_answers)):\n    short_answers[i] += ' <EOS>'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:01.766782Z","iopub.execute_input":"2024-12-08T16:39:01.767169Z","iopub.status.idle":"2024-12-08T16:39:01.772130Z","shell.execute_reply.started":"2024-12-08T16:39:01.767131Z","shell.execute_reply":"2024-12-08T16:39:01.771102Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"questions_int = []\nfor question in short_questions:\n    ints = []\n    for word in question.split():\n        if word not in questions_vocab_to_int:\n            ints.append(questions_vocab_to_int['<UNK>'])\n        else:\n            ints.append(questions_vocab_to_int[word])\n    questions_int.append(ints)\n    \nanswers_int = []\nfor answer in short_answers:\n    ints = []\n    for word in answer.split():\n        if word not in answers_vocab_to_int:\n            ints.append(answers_vocab_to_int['<UNK>'])\n        else:\n            ints.append(answers_vocab_to_int[word])\n    answers_int.append(ints)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:18.509027Z","iopub.execute_input":"2024-12-08T16:39:18.509415Z","iopub.status.idle":"2024-12-08T16:39:18.517471Z","shell.execute_reply.started":"2024-12-08T16:39:18.509378Z","shell.execute_reply":"2024-12-08T16:39:18.515940Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(len(questions_int))\nprint(len(answers_int))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:28.228975Z","iopub.execute_input":"2024-12-08T16:39:28.229345Z","iopub.status.idle":"2024-12-08T16:39:28.235511Z","shell.execute_reply.started":"2024-12-08T16:39:28.229311Z","shell.execute_reply":"2024-12-08T16:39:28.234107Z"}},"outputs":[{"name":"stdout","text":"177\n177\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"word_count = 0\nunk_count = 0\n\nfor question in questions_int:\n    for word in question:\n        if word == questions_vocab_to_int[\"<UNK>\"]:\n            unk_count += 1\n        word_count += 1\n    \nfor answer in answers_int:\n    for word in answer:\n        if word == answers_vocab_to_int[\"<UNK>\"]:\n            unk_count += 1\n        word_count += 1\n    \nunk_ratio = round(unk_count/word_count,4)*100\n    \nprint(\"Total number of words:\", word_count)\nprint(\"Number of times <UNK> is used:\", unk_count)\nprint(\"Percent of words that are <UNK>: {}%\".format(round(unk_ratio,3)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:42.356331Z","iopub.execute_input":"2024-12-08T16:39:42.356846Z","iopub.status.idle":"2024-12-08T16:39:42.368918Z","shell.execute_reply.started":"2024-12-08T16:39:42.356798Z","shell.execute_reply":"2024-12-08T16:39:42.367279Z"}},"outputs":[{"name":"stdout","text":"Total number of words: 2864\nNumber of times <UNK> is used: 1330\nPercent of words that are <UNK>: 46.44%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\nsorted_questions = []\nsorted_answers = []\n\nfor length in range(1, max_line_length+1):\n    for i in enumerate(questions_int):\n        if len(i[1]) == length:\n            sorted_questions.append(questions_int[i[0]])\n            sorted_answers.append(answers_int[i[0]])\n\nprint(len(sorted_questions))\nprint(len(sorted_answers))\nprint()\nfor i in range(3):\n    print(sorted_questions[i])\n    print(sorted_answers[i])\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:39:58.189138Z","iopub.execute_input":"2024-12-08T16:39:58.189584Z","iopub.status.idle":"2024-12-08T16:39:58.197752Z","shell.execute_reply.started":"2024-12-08T16:39:58.189541Z","shell.execute_reply":"2024-12-08T16:39:58.196466Z"}},"outputs":[{"name":"stdout","text":"177\n177\n\n[52, 6, 10]\n[52, 31, 52, 45, 51]\n\n[52, 52, 10]\n[52, 52, 20, 34, 52, 52, 45, 51]\n\n[52, 0, 52, 1]\n[15, 52, 52, 52, 51]\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"pip install transformers datasets torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:50:00.611885Z","iopub.execute_input":"2024-12-08T16:50:00.612639Z","iopub.status.idle":"2024-12-08T16:50:12.953530Z","shell.execute_reply.started":"2024-12-08T16:50:00.612531Z","shell.execute_reply":"2024-12-08T16:50:12.951932Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:50:39.820659Z","iopub.execute_input":"2024-12-08T16:50:39.821219Z","iopub.status.idle":"2024-12-08T16:50:40.877282Z","shell.execute_reply.started":"2024-12-08T16:50:39.821145Z","shell.execute_reply":"2024-12-08T16:50:40.875812Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"dataset_list = lengths.to_dict(orient='records')\n\n# Create a Hugging Face Dataset\ndataset = Dataset.from_list(dataset_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:51:31.392423Z","iopub.execute_input":"2024-12-08T16:51:31.393350Z","iopub.status.idle":"2024-12-08T16:51:31.452075Z","shell.execute_reply.started":"2024-12-08T16:51:31.393283Z","shell.execute_reply":"2024-12-08T16:51:31.450512Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:52:29.208228Z","iopub.execute_input":"2024-12-08T16:52:29.208621Z","iopub.status.idle":"2024-12-08T16:52:29.215800Z","shell.execute_reply.started":"2024-12-08T16:52:29.208587Z","shell.execute_reply":"2024-12-08T16:52:29.214580Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Answer'],\n    num_rows: 177\n})"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\n# Load the GPT2 tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\n# Set the padding token to eos_token\ntokenizer.pad_token = tokenizer.eos_token\n\n# Tokenize the 'Question' and 'Answer' columns\ndef tokenize_function(examples):\n    # Tokenize input and output\n    inputs = tokenizer(examples['Question'], padding=\"max_length\", truncation=True, max_length=128)\n    outputs = tokenizer(examples['Answer'], padding=\"max_length\", truncation=True, max_length=128)\n    return {'input_ids': inputs['input_ids'], 'labels': outputs['input_ids']}\n\n# Apply tokenization to the dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:54:19.870249Z","iopub.execute_input":"2024-12-08T16:54:19.870660Z","iopub.status.idle":"2024-12-08T16:54:21.769074Z","shell.execute_reply.started":"2024-12-08T16:54:19.870622Z","shell.execute_reply":"2024-12-08T16:54:21.767671Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/177 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d076becf51c84b3d92b133256974f684"}},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel\n\n# Load the pre-trained GPT2 model\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:54:46.316781Z","iopub.execute_input":"2024-12-08T16:54:46.317199Z","iopub.status.idle":"2024-12-08T16:54:51.869474Z","shell.execute_reply.started":"2024-12-08T16:54:46.317142Z","shell.execute_reply":"2024-12-08T16:54:51.868281Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08000b34b53b44f1b3ecc2dd07e4e4fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04097c2a56e745a3a6765017b0b89fb1"}},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',  # Output directory for the model\n    evaluation_strategy=\"epoch\",  # Evaluate every epoch\n    learning_rate=5e-5,\n    per_device_train_batch_size=8,  # Batch size\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,  # Number of epochs\n    weight_decay=0.01,\n    logging_dir='./logs',  # Logs directory\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_dataset,  # Optionally, you can split the dataset\n)\n\n# Fine-tune the model\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T16:54:59.985159Z","iopub.execute_input":"2024-12-08T16:54:59.985892Z","iopub.status.idle":"2024-12-08T17:07:58.279884Z","shell.execute_reply.started":"2024-12-08T16:54:59.985852Z","shell.execute_reply":"2024-12-08T17:07:58.278061Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241208_165541-bnju8r16</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/i210319-national-university-of-/huggingface/runs/bnju8r16' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/i210319-national-university-of-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/i210319-national-university-of-/huggingface' target=\"_blank\">https://wandb.ai/i210319-national-university-of-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/i210319-national-university-of-/huggingface/runs/bnju8r16' target=\"_blank\">https://wandb.ai/i210319-national-university-of-/huggingface/runs/bnju8r16</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [69/69 12:05, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.437747</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.342805</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.313356</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=69, training_loss=1.7166374317113904, metrics={'train_runtime': 773.4197, 'train_samples_per_second': 0.687, 'train_steps_per_second': 0.089, 'total_flos': 34686517248000.0, 'train_loss': 1.7166374317113904, 'epoch': 3.0})"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# Generate response using the fine-tuned model\ndef generate_response(input_text):\n    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n    chat_history_ids = model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n    return tokenizer.decode(chat_history_ids[0], skip_special_tokens=True)\n\n# Test the model\nresponse = generate_response(\"آپ کہاں جا رہے ہیں؟\")\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:09:14.406934Z","iopub.execute_input":"2024-12-08T17:09:14.407443Z","iopub.status.idle":"2024-12-08T17:09:14.833706Z","shell.execute_reply.started":"2024-12-08T17:09:14.407392Z","shell.execute_reply":"2024-12-08T17:09:14.832628Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"آپ کہاں جا رہے ہیں؟ہہہہ\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\n# Load pre-trained DialoGPT model\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:09:58.575050Z","iopub.execute_input":"2024-12-08T17:09:58.575520Z","iopub.status.idle":"2024-12-08T17:10:05.098679Z","shell.execute_reply.started":"2024-12-08T17:09:58.575473Z","shell.execute_reply":"2024-12-08T17:10:05.097153Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c8e8646ff384768b6404f709af41dac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45aa0cd4a81542e5915beb945528b3ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b064b5ae7e4bd5827bcf5807b3db8b"}},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./dialoggpt_finetuned\",  # output directory\n    evaluation_strategy=\"epoch\",  # Evaluate every epoch\n    learning_rate=5e-5,\n    per_device_train_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\n# Define the trainer\ntrainer = Trainer(\n    model=model,                           # the model to train\n    args=training_args,                    # training arguments\n    train_dataset=tokenized_dataset,  \n    eval_dataset = tokenized_dataset,# training dataset\n    tokenizer=tokenizer,                   # tokenizer\n)\n\n# Start training\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T17:11:03.434069Z","iopub.execute_input":"2024-12-08T17:11:03.434665Z","iopub.status.idle":"2024-12-08T17:46:52.332287Z","shell.execute_reply.started":"2024-12-08T17:11:03.434600Z","shell.execute_reply":"2024-12-08T17:46:52.330832Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_24/2864353507.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [135/135 35:31, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.517178</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.391605</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.360780</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=135, training_loss=1.6125577573423033, metrics={'train_runtime': 2147.8785, 'train_samples_per_second': 0.247, 'train_steps_per_second': 0.063, 'total_flos': 123285017198592.0, 'train_loss': 1.6125577573423033, 'epoch': 3.0})"},"metadata":{}}],"execution_count":55}]}